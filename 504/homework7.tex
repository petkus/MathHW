\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsthm, epsfig}

\newenvironment{definition}{\vspace{2 ex}{\noindent{\bf Definition}}}
        {\vspace{2 ex}}

\newenvironment{ques}[1]{\textbf{Exersise #1}\vspace{1 mm}\\ }{\bigskip}

\renewcommand{\theenumi}{\alph{enumi}}

\theoremstyle{definition}

\newenvironment{Proof}{\noindent {\sc Proof.}}{$\Box$ \vspace{2 ex}}
\newtheorem{Wp}{Writing Problem}
\newtheorem{Ep}{Extra Credit Problem}

\oddsidemargin-1mm
\evensidemargin-0mm
\textwidth6.5in
\topmargin-15mm
\textheight8.75in
\footskip27pt


\renewcommand{\l}{\left }
\renewcommand{\r}{\right }

\newcommand{\R}{\mathbb R}
\newcommand{\Q}{\mathbb Q}
\newcommand{\Z}{\mathbb Z}
\newcommand{\C}{\mathbb C}
\newcommand{\N}{\mathbb N}
\renewcommand{\H}{\mathbb H}

\newcommand{\s}{\sin}
\renewcommand{\c}{\cos}

\renewcommand{\t}{\theta}
\renewcommand{\a}{\alpha}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\T}{\mathcal{T}}

\newcommand{\Tor}{\text{Tor}}
\newcommand{\Ann}{\text{Ann}}

\pagestyle{empty}
\begin{document}

\noindent \textit{\textbf{Math 504, Fall 2017}} \hspace{1.3cm}
\textit{\textbf{HOMEWORK $\#$6}} \hspace{1.3cm} \textit{\textbf{Peter
Gylys-Colwell}} 

\vspace{1cm}

\begin{ques}{7.1}
	(1) \ We have that the set $I = \{g \in k[x]: g(T)\}$ is an ideal of $k[x]$.
	Thus since $k[x]$ is a PID, we know it is generated by one element. This
	element is $m_T$ since if there was a different generator $g$ of $I$ which
	is not a unit multiple of $m_T$ then $g$ has degree less than degree of
	$m_T$ and $g(T) = 0$ which contradicts minimality of $m_T$. Thus we have
	that for any $f \in k[x]$, $f(T) = 0 \Leftrightarrow f \in I
	\Leftrightarrow$ $m_T$ divides $f$\\
	\\
	(2) \ We know that 
	$$V \cong k[x]/a_1(x) \oplus k[x]/a_2(x) \dots \oplus k[x]/a_{n-1}(x)
	\oplus k[x]/m_T(x)$$
	With $a_1|a_2| \dots a_{n-1} | m_T$. Thus in order for $f \in
	\Ann_{k[x]}(V)$, it would have to be the case that $a_1 | f, a_2 | f, \dots
	m_T | f$. Which is equivalent to $m_T | f$ since $a_1, a_2 \dots a_{n-1} |
	m_T$. Thus $\Ann_{k[x]}(V) = (m_T)$
\end{ques}

\begin{ques}{7.2}
	(1) \ $A$ is already in rational canonical form so $P$ is just the identity
	matrix. We have that det$(xI - A)$ is precisely $(x - 1)(x^2 - 3x + 2)$
	which is the characteristic polinomial.\\
	(2) \ We have that the characteristic polinomial splits completely as $(x -
	1)^2(x - 2)$, so the eigenvalues are $1, 1, 2$. Thus the jordan form is
	$$J = \begin{bmatrix}
	1 & 0 & 0\\
	0 & 1 & 0\\
	0 & 0 & 2\\
	\end{bmatrix}$$
	I solved the equations $Av = v, Aw = 2w$ to get eigenvectors. We
	get that the eigenvectors are $[0\ -1\ 1], [1\ 0\ 0], [0\ -2\ 1]$ for
	eigenvalues $2, 1, 1$ respectivly. Thus we know that $S^{-1}JS = A$ where
	$S$ is the matrix of eigenvectors. So $P^{-1} = S$, a straightforward
	inverse computation gives us $P$
	$$P^{-1} = \begin{bmatrix}
	0 & 1 & 0\\
	-1 & 0 & -2\\
	1 & 0 & 1\\
	\end{bmatrix} \Rightarrow
	P = \begin{bmatrix}
	0 & 1 & 2\\
	1 & 0 & 0\\
	0 & -1 & -1\\
	\end{bmatrix}
	$$
\end{ques}

\begin{ques}{7.3}
	(1) \ We have that the only possible reduced forms of the $k[x]$ modules are
	$$V \cong k[x]/(x) \oplus k[x]/(x(x^2+1)^2)$$
	$$V \cong k[x]/(x^2 + 1) \oplus k[x]/(x^2(x^2+1))$$
	$$V \cong k[x]/(x(x^2 + 1)) \oplus k[x]/(x(x^2+1))$$
	Factoring $x(x^2+1)^2 = x^5 + 2x^3 + x$, $x^2(x^2 + 1) = x^4 + x^2, x(x^2 +
	1) = x^3 + x$ we have the corresponding rational canonical forms
	$$\begin{bmatrix} 
	1 & 0 & 0 & 0 & 0 & 0\\ 
	0 & 0 & 0 & 0 & 0 & 0\\ 
	0 & 1 & 0 & 0 & 0 & -1\\ 
	0 & 0 & 1 & 0 & 0 & 0\\ 
	0 & 0 & 0 & 1 & 0 & -2\\ 
	0 & 0 & 0 & 0 & 1 & 0\\ 
	\end{bmatrix}
	\begin{bmatrix} 
	0 & -1 & 0 & 0 & 0 & 0\\ 
	1 & 0 & 0 & 0 & 0 & 0\\ 
	0 & 0 & 0 & 0 & 0 & 0\\ 
	0 & 0 & 1 & 0 & 0 & 0\\ 
	0 & 0 & 0 & 1 & 0 & -1\\ 
	0 & 0 & 0 & 0 & 1 & 0\\ 
	\end{bmatrix}
	\begin{bmatrix} 
	0 & 0 & 0 & 0 & 0 & 0\\ 
	1 & 0 & -1 & 0 & 0 & 0\\ 
	0 & 1 & 0 & 0 & 0 & 0\\ 
	0 & 0 & 0 & 0 & 0 & -1\\ 
	0 & 0 & 0 & 1 & 0 & 0\\ 
	0 & 0 & 0 & 0 & 1 & 0\\ 
	\end{bmatrix}$$
	\\
	(2), (3) \ $A$ has order $4$  means that $A$ has a minimal polinomial
	$M_A(x)$ which divides $x^4 - 1$. $x^4 - 1$ splits as $(x^2 + 1)(x+1)(x-1)$
	in $\Q$ and splits fully as $(x - 1)(x + 1)(x - i)(x + i)$ over $\C$. Thus
	the only possible degree $2$ $\Q[x]$ modules are
	$$\Q[x]/(x^2 - 1), \Q[x]/(x^2 + 1), \Q[x]/(x + 1)\oplus \Q[x]/(x + 1), \Q[x]/(x
	- 1)\oplus \Q[x]/(x - 1)$$
	Which leads to the matricies
	$$\begin{bmatrix} 
	0 & 1 \\ 
	1 & 0
	\end{bmatrix}
	\begin{bmatrix} 
	0 & -1 \\ 
	1 & 0
	\end{bmatrix}
	\begin{bmatrix} 
	0 & 1 \\ 
	-1 & 0
	\end{bmatrix}
	\begin{bmatrix} 
	0 & -1 \\ 
	-1 & 0
	\end{bmatrix}
	\begin{bmatrix} 
	-1 & 0 \\ 
	0 & -1
	\end{bmatrix}
	\begin{bmatrix} 
	-1 & 0 \\ 
	0 & 1
	\end{bmatrix}
	\begin{bmatrix} 
	1 & 0 \\ 
	0 & -1
	\end{bmatrix}
	$$
	A quick computation yields that the only elements of order $4$ are 
	$$
	\begin{bmatrix} 
	0 & -1 \\ 
	1 & 0
	\end{bmatrix}
	\begin{bmatrix} 
	0 & 1 \\ 
	-1 & 0
	\end{bmatrix}
	$$
	For the complex case, on top of the matricies in $\Q$ we also have the
	possible $\C[x]$ modules 
	$$\C[x]/(x^2 \pm (1 + i)x + i), \C[x]/(x^2 \pm (1 - i)x - i)$$
	$$\C[x]/(x \pm i)\oplus \C[x]/(x \pm i), \C[x]/(x \pm i)\oplus \C[x]/(x \pm 1)$$
	This yields the matricies
	$$\begin{bmatrix} 
	0 & -i \\ 
	1 & \pm(1 + i)
	\end{bmatrix}
	\begin{bmatrix} 
	0 & i \\ 
	-1 & \pm(1 - i)
	\end{bmatrix}
	\begin{bmatrix} 
	\pm i & 0 \\ 
	0 & \pm i
	\end{bmatrix}
	\begin{bmatrix} 
	\pm 1 & 0 \\ 
	0 & \pm i
	\end{bmatrix}
	\begin{bmatrix} 
	\pm i & 0 \\ 
	0 & \pm 1
	\end{bmatrix}
	$$
	A straightforward computation yields that every one of these matricies is
	of order $4$ (none have order $2$)
\end{ques}

\begin{ques}{7.4}
	$R$ is right Noetherian by the following reasoning. For any chain of ideals $0
	\subset I_1 \subset I_2 \subset \dots I_n \subset \dots R$, if the chain
	does not terminate then we can choose elements
	$$A_1, 	A_2, A_3, \dots 
	A_i = \begin{bmatrix} 
	a_i & b_i \\ 
	0 & c_i
	\end{bmatrix} \dots
	$$
	where $A_i \in I_i, A_{i+1} \in I_{i+1}$ and $A_{i+1} \notin I_i$. We have
	that $A_1R + A_2R + \dots A_iR \subset I_i$. We have $A_iR$ is of the form
	$$A_iR = \l\{\begin{bmatrix} 
	a_in & a_ip + b_iq \\ 
	0 & c_iq
	\end{bmatrix} | n \in \Z, p,q \in \Q \r\} = 
	\l \{ \begin{bmatrix} 
	a_in & p \\ 
	0 & q
	\end{bmatrix} | n \in \Z, p,q \in \Q\r\} 
	$$
	Thus we have that 
	$$A_1R + A_2R + \dots A_iR = 
	\l \{ \begin{bmatrix} 
	\text {gcd}(a_1, \dots a_i)n & p \\ 
	0 & q
	\end{bmatrix} | n \in \Z, p,q \in \Q\r\} 
	$$
	Since $A_{i+1}R \not \subseteq A_1R + A_2R + \dots A_iR$, we know that $\text
	{gcd}(a_1, \dots a_i) \not |a_{i+1}$ and thus we have that $\text
	{gcd}(a_1, \dots a_i) < \text {gcd}(a_1, \dots a_{i+1})$. So in a finite
	amount of iterations, there is an $n$ such that $\text {gcd}(a_1, \dots
	a_n) = 1$ which means
	$$A_1R + A_2R + \dots A_nR = R \Rightarrow I_n = R$$
	\\
	$R$ is not left Noetherian as illustrated in this chain
	$$R \begin{bmatrix} 
	1 & 1 \\ 
	0 & 0
	\end{bmatrix}
	\subset
	R \begin{bmatrix} 
	1 & \frac 1 2 \\ 
	0 & 0
	\end{bmatrix}
	\subset
	R \begin{bmatrix} 
	1 & \frac 1 4 \\ 
	0 & 0
	\end{bmatrix} 
	\subset
	\dots \subset
	R \begin{bmatrix} 
	1 & \frac 1 {2^n} \\ 
	0 & 0
	\end{bmatrix}  \subset \dots$$
	Elements of each Ideal are of the form
	$$\begin{bmatrix} 
	z & z \\ 
	0 & 0
	\end{bmatrix}
	,
	\begin{bmatrix} 
	z & \frac z 2 \\ 
	0 & 0
	\end{bmatrix}
	,
	\begin{bmatrix} 
	z & \frac z 4 \\ 
	0 & 0
	\end{bmatrix} 
	\dots 
	\begin{bmatrix} 
	1 & \frac z {2^n} \\ 
	0 & 0
	\end{bmatrix}   \dots$$
	For $z \in \Z$ and are thus each proper ideals.
\end{ques}

\begin{ques}{7.5}
	(1) \ Let $g_1 \dots g_n$ be a basis for $R$ over $k$. We can consider the
	number of these generators in an ideal $I$ which we will denote by $d(I)$.
	For any ascending chain
	$$0 \subset I_1 \subset I_2 \dots I_k \subset \dots \subset R$$
	Since $I_i \subset I_{i+1}$ we know that $d(I_i) \leq d(I_{i+1})$. Also
	notice that if $d(I_i) = d(I_{i+1})$ then $I_i = I_{i+1}$. This is because
	the set of generators in $I_i$ and $I_{i+1}$ must be the same since $I_i
	\subseteq I_{i+1}$. Thus for any $a \in I_{i + 1}$ we can write it as a
	linear combination of those generators in $I_{i+1}$ and thus $a$ is in
	$I_i$ as well. Thus we have a monotonic bounded sequence in the integers.
	$$0 \leq d(I_1) \leq d(I_2) \leq \dots d(I_k) \dots \leq n$$
	Thus it must be constant after some $N$. So $I_N = I_{N+1} = I_{N+2} \dots $ 
	the chain terminates. The same reasoning shows $R$ is artinian. For any
	descending chain
	$$R \supseteq I_1 \supseteq I_2 \dots I_k \supseteq  \dots \supset 0$$
	We have a monotonic bounded sequence
	$$n \geq d(I_1) \geq \dots d(I_k) \geq \dots 0$$
	And thus past some $N$ $d(I_k)$ is constant so $I_N = I_{N+1} = I_{N+2} \dots$
	the chain terminates.\\
	\\
	(2) \ $R/I$ is also a PID and thus Noetherian. We know PIDs are Noetherian
	since if we consider an infinite chain $0 \subseteq I_1 \subseteq I_2
	\subseteq \dots I_k \subseteq \dots R/I$ the union of all these ideals is an
	ideal (and principle) $J = \bigcup_{k \in \N} I_k = a(R/I)$. Thus $a$ must
	be in one of the $I_k$ and then the chain is constant past that ideal.\\
	We can do a similar argument for Artinian. If we have a descending chain
	$R/I \supseteq I_1/I \supseteq I_2/I \supseteq \dots I_k/I \supseteq \dots
	\supseteq I$ then the intersection of all these ideals is an ideal $J=
	\bigcap_{k\in\N} I_k = (a)$. We have that $I \subseteq J$ and therefore letting
	$I = (b) \neq 0$ we have that $a | b$ so $a \neq 0$. Thus since PIDs are
	UFDs, $a$ has a factorization 
	$$a = p_1^{n_1}p_2^{n_2} \dots p_k^{n_k}$$
	For each $I_i = (a_i)$ of our chain, we have that $a_i | a$ and $a_i |
	a_{i+1}$. Thus if we consider the number of prime factors of $a$ present in
	$a_i$ which we will denote as $d(a_i)$, we have a bounded monotonic
	sequence in $\N$
	$$d(a_1) \leq d(a_2) \leq \dots d(a_k) \leq \dots d(a)$$
	Thus it converges. So for some $N \in \N$, $d(a_N) = d(a_{N+1}) =
	d(a_{N+2}) \dots$ which means $a_N = a_{N+1} \dots  \Rightarrow I_N =
	I_{N+1} = I_{N+2} \dots $
\end{ques}

\begin{ques}{7.6}
	(1) \ If we consider any nonzero ideal $I$, then there is an $A \in I$ with
	$\det A \neq 0$. The reason for this is because if $B \in I$ with $\det B =
	0$ then we can perform row operations (which works the same as in
	the vector space case) to get $B$ in diagonalized form. This diagonalized
	form $B'$ is still in $I$ since it is the product of row operation
	matricies with an element in $I$. 
	$$B' = \begin{bmatrix}
	b_1 & 0 & \dots & \dots &0\\
	0 & b_2 & \dots & \dots &0\\
	\vdots & 0 & \ddots &\dots & \vdots\\
	0& \dots & 0 & b_m &  \ddots\\
	0 & \dots & 0 & 0 \ddots & \vdots\\
	\end{bmatrix}
	$$
	
	we now have that $AR \subseteq I$ and $RA \subseteq I$. However $A$ is a
	unit and thus $R = AR = RA = I$. The reason $A$ is a unit is because we can
	perform row operations in $D$ the same as over a vector space until we get
	the identity matrix since $A$ has invertable determinant.\\
	\\
	(2) \ It is clear that $I_k$ is closed under addition since we add
	component-wise so the columns that are not the $k$th column will stay zero.\\
	$I_k$ is a left ideal since for any $A \in R, B \in I_k$, 
	$$(AB)_{m,l} = \sum_{i = 0}^n A_{m,i}B_{i,l}$$
	Thus for every $l \neq k$ we get that $B_{i,l} = 0$ so $(AB)_{m,l} = 0$ so
	$AB$ has zero columns for every column that is not the $k$th column. Thus
	$AB \in I_k$. So $I_k$ is a left ideal.
\end{ques}

\end{document}
